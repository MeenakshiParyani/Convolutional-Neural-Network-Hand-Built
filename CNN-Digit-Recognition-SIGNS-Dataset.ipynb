{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import division\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.1 (70pts) Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# One hot encode the labels\n",
    "def one_hot_encode(y):\n",
    "    targets = np.array(np.unique(y)).reshape(-1)\n",
    "    enc = np.eye(len(targets))[y]\n",
    "    print(enc)\n",
    "    return enc\n",
    "\n",
    "# Get the loss of for the training example\n",
    "def cross_entropy(Y, Yhat):\n",
    "    m= Y.shape[1]\n",
    "    eps=1e-15\n",
    "    Yhat = np.clip(Yhat, eps, 1-eps)\n",
    "    loss = np.multiply(np.log(Yhat),Y) + np.multiply((1.-Y), np.log(1. - Yhat))\n",
    "    loss = np.sum(loss)\n",
    "    cost = -1./m * np.sum(loss)\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost\n",
    "\n",
    "# Applying Sigmoid Activation function to the hidden layer outputs used while forward propagation\n",
    "# Purpose of this method is to do squishing on the linear function\n",
    "def sigmoid(z):\n",
    "    print(\"Before sigmoid---\")\n",
    "    print(z)\n",
    "    sigmoid = 1 / (1 + np.exp(-z))\n",
    "    print(\"After sigmoid---\")\n",
    "    print(sigmoid)\n",
    "    return sigmoid\n",
    "\n",
    "# Applying Sigmoid Activation function to the hidden layer outputs used while backward propagation to get gradients\n",
    "# Purpose of this method is to do undo the squishing on the linear function\n",
    "def sigmoid_prime(z):\n",
    "    inv = (np.exp(-z))/(np.power((1+np.exp(-z)),2))\n",
    "    return inv\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(z,0)\n",
    "    \n",
    "def relu_prime(z):\n",
    "    return np.where(z < 0, 0.0, 1.0)\n",
    "\n",
    "# Softmax activation function to get the probablity of the classes\n",
    "def softmax(z):\n",
    "    softMax = (np.exp(z) / np.sum(np.exp(z),axis=0))\n",
    "    softMax = np.matrix(np.argmax(softMax,axis=0)).T\n",
    "    return softMax\n",
    "\n",
    "def zero_pad(X, pad):\n",
    "    ## Pads the height and width and breadth only by 'pad' columns using constant value, 4 dimensional padding\n",
    "    padded_array = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0,0)), 'constant', constant_values = (0,0))\n",
    "    print(\"Dimension after padding\" + str(padded_array.shape))\n",
    "    return padded_array\n",
    "\n",
    "# Convolution of a slice\n",
    "def convolute_slice(a_slice, W, b):\n",
    "    conv = np.multiply(a_slice, W)\n",
    "    z = np.sum(conv) + float(b)\n",
    "    return z\n",
    "\n",
    "# Calculate the coordinates of the slice\n",
    "def get_slice_coordinates(stride, f, w, h):\n",
    "    vert_start = h * stride\n",
    "    vert_end = vert_start + f\n",
    "    horiz_start = w * stride\n",
    "    horiz_end = horiz_start + f\n",
    "    return vert_start, vert_end, horiz_start, horiz_end\n",
    "\n",
    "# Flatten the array\n",
    "def flatten(A):\n",
    "    (m, nH, nW, nC) = A.shape\n",
    "    print('Shape before flattening is----')\n",
    "    print(A.shape)\n",
    "    A = A.reshape(m, nH * nW * nC)\n",
    "    print('Shape after flattening is----')\n",
    "    print(A.shape)\n",
    "    return A.transpose()\n",
    "\n",
    "def convolute_forward(A_prev, W, b, hyper_params):\n",
    "    # Get the required parameters\n",
    "    m, nH_prev, nW_prev, nC_prev = A_prev.shape\n",
    "    f, f, nC_prev, nC  = W.shape\n",
    "    pad = hyper_params[\"pad\"]\n",
    "    stride = hyper_params[\"stride\"]\n",
    "    print('convolution nH_prev, f, pad, stride---------------')\n",
    "    print(nH_prev, f, pad, stride)\n",
    "    # Calculate the dimensions of input\n",
    "    nH = int((nH_prev -f + 2 * pad)/stride) + 1\n",
    "    nW = int((nW_prev -f + 2 * pad)/stride) + 1\n",
    "    print('convolution m, nH, nW, nC---------------')\n",
    "    print(m, nH, nW, nC)\n",
    "    # Calculate the dimensions of output\n",
    "    Z = np.zeros((m, nH, nW, nC))\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    # referring professor's code for forward propagation\n",
    "    for i in range(m):\n",
    "        a_pad_prev = A_prev_pad[i, :, :, :]\n",
    "        for h in range(nH):\n",
    "            for w in range(nW):\n",
    "                for c in range(nC):\n",
    "                    # Find the coordinates of the current slice\n",
    "                    vert_start, vert_end, horiz_start, horiz_end = get_slice_coordinates(stride, f, w, h)\n",
    "                    \n",
    "                    # Extract the slice from input\n",
    "                    a_slice_prev = a_pad_prev[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "\n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron\n",
    "                    Z[i, h, w, c] = convolute_slice(a_slice_prev, W[:, :, :, c], b[:, :, :, c])\n",
    "                    \n",
    "    cache = (A_prev, W, b, hyper_params)\n",
    "    return Z\n",
    "\n",
    "def pool_forward(A_prev, hyper_params, pooling_method):\n",
    "    # Get the required parameters\n",
    "    (m, nH_prev, nW_prev, nC_prev) = A_prev.shape\n",
    "    print('Pooling (m, nH_prev, nW_prev, nC_prev---------------')\n",
    "    print(m, nH_prev, nW_prev, nC_prev)\n",
    "    f = hyper_params[\"f\"]\n",
    "    stride = hyper_params[\"stride\"]\n",
    "    print('Pooling f, stride')\n",
    "    print(f, stride)\n",
    "    # Calculate the dimensions of the output\n",
    "    nH = int(1 + (nH_prev - f) / stride)\n",
    "    nW = int(1 + (nW_prev - f) / stride)\n",
    "    nC = nC_prev\n",
    "    #print(nH, nW, nC)\n",
    "    # Initialize the output matrix\n",
    "    A = np.zeros((m, nH, nW, nC))\n",
    "    \n",
    "    for i in range(m):\n",
    "        for h in range(nH):\n",
    "            for w in range(nW):\n",
    "                for c in range(nC):\n",
    "                    \n",
    "                    # Find the coordinates of the current slice\n",
    "                    vert_start, vert_end, horiz_start, horiz_end = get_slice_coordinates(stride, f, w, h)\n",
    "                    \n",
    "                     # Extract the slice from input\n",
    "                    a_slice_prev = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    \n",
    "                    # Perform the pooling on the slice\n",
    "                    if(pooling_method == \"max\"):\n",
    "                        A[i, h, w, c] = np.max(a_slice_prev)\n",
    "                    elif(pooling_method == \"avg\"):\n",
    "                        A[i, h, w, c] = np.mean(a_slice_prev)\n",
    "    cache = (A_prev, hyper_params)                \n",
    "    assert(A.shape == (m, nH, nW, nC))\n",
    "    return A\n",
    "        \n",
    "             \n",
    "def convolute_backward(dZ, A_prev, W, b, hyper_params):\n",
    "    # Get the input dimensions\n",
    "    (m, nH_prev, nW_prev, nC_prev) = A_prev.shape\n",
    "    \n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    stride = hyper_params[\"stride\"]\n",
    "    pad = hyper_params[\"pad\"]\n",
    "    (m, nH, nW, nC) = dZ.shape\n",
    "    dA_prev = np.zeros((m, nH_prev, nW_prev, nC_prev))                           \n",
    "    dW = np.zeros((f, f, nC_prev, nC))\n",
    "    db = np.zeros((1, 1, 1, n_C))\n",
    "    A_pad_prev = zero_pad(A_prev, pad)\n",
    "    dA_pad_prev = zero_pad(dA_prev, pad)\n",
    "    \n",
    "    for i in range(m):\n",
    "        \n",
    "        a_pad_prev = A_pad_prev[i,:,:,:]\n",
    "        da_pad_prev = dA_pad_prev[i,:,:,:]\n",
    "        \n",
    "        for h in range(nH):\n",
    "            for w in range(nW):\n",
    "                for c in range(nC):\n",
    "\n",
    "                    # Find the coordinates of the current slice\n",
    "                    vert_start, vert_end, horiz_start, horiz_end = get_slice_coordinates(stride, f, w, h)\n",
    "\n",
    "                    # Extract the slice from input\n",
    "                    a_slice = A_pad_prev[i, vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "\n",
    "                    da_pad_prev[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]\n",
    "                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
    "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
    "    \n",
    "        #dA_prev[i, :, :, :] = da_pad_prev[pad:-pad, pad:-pad, :]\n",
    "    assert(dA_prev.shape == (m, nH_prev, nW_prev, nC_prev))\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "# Backward pass for max pooling for a slice\n",
    "def backprop_max_pooling(x):\n",
    "    mask = x==np.max(x)\n",
    "    return mask\n",
    "\n",
    "# Backward pass for avg pooling for a slice\n",
    "def backprop_avg_pooling(dz, slice_shape):\n",
    "    (nH, nW) = slice_shape\n",
    "    avg = dz/(nH * nW) # calculate avg\n",
    "    a = np.ones((nH, nW)) * avg\n",
    "    return a\n",
    "\n",
    "\n",
    "def pool_backward(dA, A_prev, hyper_params, pooling_method):\n",
    "    stride = hyper_params[\"stride\"]\n",
    "    f = hyper_params[\"f\"]\n",
    "    m, nH_prev, nW_prev, nC_prev = A_prev.shape\n",
    "    m, nH, nW, nC = dA.shape\n",
    "    dA_prev = np.zeros((m, nH_prev, nW_prev, nC_prev))\n",
    "    \n",
    "    for i in range(m):\n",
    "        a_prev = A_prev[i,:,:,:]\n",
    "        for h in range(nH):\n",
    "            for w in range(nW):\n",
    "                for c in range(nC):\n",
    "                    \n",
    "                    # Find the coordinates of the current slice\n",
    "                    vert_start, vert_end, horiz_start, horiz_end = get_slice_coordinates(stride, f, w, h)\n",
    "                    #print(\"coordinate\")\n",
    "                    #print(vert_start, vert_end, horiz_start, horiz_end)\n",
    "                    if(pooling_method == \"max\"):\n",
    "                        a_slice_prev = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]                  \n",
    "                        mask = backprop_max_pooling(a_slice_prev)\n",
    "                        temp = mask * dA[i, h, w, c]\n",
    "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += temp\n",
    "\n",
    "                    elif(pooling_method == \"avg\"):\n",
    "                        da = dA[i, h, w, c]\n",
    "                        shape = (f,f)\n",
    "                        #print('-----------dAprev shape---------')\n",
    "                        #print(dA_prev.shape)\n",
    "                        #print('-----------temp---------')\n",
    "                        temp = backprop_avg_pooling(da, shape)\n",
    "                        #print(temp.shape)\n",
    "                        #print('--------------dAPrev----------')\n",
    "                        #print(dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c])\n",
    "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += temp\n",
    "    \n",
    "    assert(dA_prev.shape == A_prev.shape)\n",
    "    return dA_prev\n",
    "\n",
    "\n",
    "# Forward propagation to calculate yHat by applying activation function twice\n",
    "def forward_propagate(cache, hyper_params, parameters):\n",
    "    \n",
    "    # Layer 1 Convolution\n",
    "    cache[\"Z1c\"] = convolute_forward(cache[\"A0\"], parameters[\"W1c\"], parameters[\"b1c\"], hyper_params[\"c1\"]) # Convolution\n",
    "    cache[\"A1c\"] = relu(cache[\"Z1c\"]) # Relu Activation\n",
    "#     print('-----------------Z1c--------------')\n",
    "#     print(cache[\"Z1c\"])\n",
    "#     print('-----------------A1c--------------')\n",
    "#     print(cache[\"A1c\"])\n",
    "    \n",
    "    # Layer 1 Pooling \n",
    "    cache[\"A1p\"] = pool_forward(cache[\"A1c\"], hyper_params[\"p1\"], pooling_method=\"max\") # Pooling\n",
    "#     print('-----------------A1p--------------')\n",
    "#     print(cache[\"A1p\"])\n",
    "    \n",
    "    # Layer 2 Convolution \n",
    "    cache[\"Z2c\"] = convolute_forward(cache[\"A1p\"], parameters[\"W2c\"], parameters[\"b2c\"], hyper_params[\"c2\"]) # Convolution\n",
    "    cache[\"A2c\"] = relu(cache[\"Z2c\"]) # Relu Activation\n",
    "#     print('-----------------Z2c--------------')\n",
    "#     print(cache[\"Z2c\"])\n",
    "#     print('-----------------A2c--------------')\n",
    "#     print(cache[\"A2c\"])\n",
    "    \n",
    "    # Layer 2 Pooling \n",
    "    cache[\"A2p\"] = pool_forward(cache[\"A2c\"],hyper_params[\"p2\"], pooling_method=\"avg\") # Pooling\n",
    "#     print('-----------------A2p--------------')\n",
    "#     print(cache[\"A2p\"])\n",
    "    \n",
    "    # Flatten the array\n",
    "    cache[\"A3\"] = flatten(cache[\"A2p\"])\n",
    "#     print('-----------------A3--------------')\n",
    "#     print(cache[\"A3\"])\n",
    "\n",
    "    # Fully Connected Layer 4\n",
    "    cache[\"Z4\"] = np.dot(parameters[\"W4\"], cache[\"A3\"]) + parameters[\"b4\"]\n",
    "    cache[\"A4\"] = relu(cache[\"Z4\"]) # Relu Activation \n",
    "#     print('-----------------Z4--------------')\n",
    "#     print(cache[\"Z4\"])\n",
    "#     print('-----------------A4--------------')\n",
    "#     print(cache[\"A4\"])\n",
    "    \n",
    "    # Fully Connected Layer 5\n",
    "    cache[\"Z5\"] = np.dot(parameters[\"W5\"], cache[\"A4\"]) + parameters[\"b5\"]\n",
    "    cache[\"A5\"] = sigmoid(cache[\"Z5\"]) # Sigmoid Activation \n",
    "#     print('-----------------Z5--------------')\n",
    "#     print(cache[\"Z5\"])\n",
    "#     print('-----------------A5--------------')\n",
    "#     print(cache[\"A5\"])\n",
    "\n",
    "    return cache\n",
    "\n",
    "\n",
    "def backward_propagate(Y, cache, hyper_params, params):\n",
    "    gradients = {}\n",
    "    # Fully Connected Layer 5\n",
    "    m = cache[\"A5\"].shape[1]\n",
    "    dZ5 = cache[\"A5\"] - Y.transpose()\n",
    "    dW5 = (1./m) * np.dot(dZ5, cache[\"A4\"].transpose())\n",
    "    db5 = (1./m) * np.sum(dZ5, axis=1)\n",
    "    gradients[\"dW5\"] = dW5\n",
    "    gradients[\"db5\"] = db5\n",
    "    \n",
    "    # Fully Connected Layer 4\n",
    "    temp1 = np.dot( params[\"W5\"].transpose(), dZ5 )\n",
    "    temp2 = relu_prime(cache[\"Z4\"])\n",
    "    dZ4 = np.multiply(temp1 , temp2) # element wise product of same dimension matrices\n",
    "    dW4 = (1./m) * np.dot(dZ4, cache[\"A3\"].transpose())\n",
    "    db4 = (1./m) * np.sum(dZ4, axis =1)\n",
    "    gradients[\"dW4\"] = dW4\n",
    "    gradients[\"db4\"] = db4\n",
    "    \n",
    "    # Un-Flaten the list\n",
    "    (m, nH, nW, nC) = cache[\"A2p\"].shape\n",
    "    dP2 = cache[\"A3\"].reshape(m, nH, nW, nC)\n",
    "    \n",
    "    dA2 = pool_backward(dP2, cache[\"A2c\"], hyper_params[\"p2\"], pooling_method=\"avg\")\n",
    "    dZ2 = relu_prime(dA2)\n",
    "    print(\"shape\")\n",
    "    print(dZ2.shape)\n",
    "    print(cache[\"Z2c\"].shape)\n",
    "    dP1, dW2, db2 = convolute_backward(dZ2, cache[\"A1p\"], params[\"W2c\"], params[\"b2c\"], hyper_params[\"c2\"])\n",
    "    gradients[\"dW2\"] = dW2\n",
    "    gradients[\"db2\"] = db2\n",
    "    \n",
    "    \n",
    "    dA1 = pool_backward(dP1, cache[\"A1c\"], hyper_params[\"p1\"], pooling_method=\"max\")\n",
    "    dZ1 = relu_prime(dA1)\n",
    "    X, dW1, db1 = convolute_backward(dZ1, cache[\"A0\"], params[\"W1c\"], params[\"b1c\"], hyper_params[\"c1\"])\n",
    "    gradients[\"dW1\"] = dW1\n",
    "    gradients[\"db1\"] = db1\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.2 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107279ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit in the image is 4\n",
      "[[ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('ex5_train_x.npy')\n",
    "y_train = np.load('ex5_train_y.npy')\n",
    "indx = 2\n",
    "plt.imshow(X_train[indx])\n",
    "plt.show()\n",
    "print(\"Digit in the image is \" + str(y_train[indx]))\n",
    "# print(X_train)\n",
    "\n",
    "# Normalize the data\n",
    "X_train_norm = X_train/255 - 0.5\n",
    "# print(X_train_norm)\n",
    "y_train_encoded = one_hot_encode(y_train)\n",
    "# X_train_padded = zero_pad(X_train, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.3 (10pts) Initialize parameters (Weights, bias for each layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(input_channl, conv1_f, channl_1, conv2_f, channl_2, \n",
    "                          input_size, fc1_size, fc2_size):\n",
    "    params = {}\n",
    "    # Convolution Layer 1 Params\n",
    "    params[\"W1c\"] =  np.random.randn(conv1_f, conv1_f, input_channl, channl_1)\n",
    "    params[\"b1c\"] =  np.zeros((1,1,1, channl_1))\n",
    "    \n",
    "    # Convolution Layer 2 Params\n",
    "    params[\"W2c\"] =  np.random.randn(conv2_f, conv2_f, channl_1, channl_2)\n",
    "    params[\"b2c\"] =  np.zeros((1,1,1,channl_2))\n",
    "    \n",
    "    # FC layer 4 params\n",
    "    params[\"W4\"] =  np.random.randn(fc1_size, input_size)\n",
    "    params[\"b4\"] =  np.zeros((fc1_size, 1))\n",
    "    \n",
    "    # FC layer 5 params\n",
    "    params[\"W5\"] =  np.random.randn(fc2_size, fc1_size)\n",
    "    params[\"b5\"] =  np.zeros((fc2_size, 1))\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_hyper_params():\n",
    "    \n",
    "    hyper_params = {}\n",
    "    \n",
    "    # Convolution Layer 1 Hyper Parameters\n",
    "    hyper_params_c1 = {}\n",
    "    hyper_params_c1[\"stride\"] = 2\n",
    "    hyper_params_c1[\"pad\"] = 1\n",
    "    \n",
    "    # Pooling Layer 1 Hyper Parameters\n",
    "    hyper_params_p1 = {}\n",
    "    hyper_params_p1[\"stride\"] = 1\n",
    "    hyper_params_p1[\"pad\"] = 0\n",
    "    hyper_params_p1[\"f\"] = 5\n",
    "    \n",
    "    # Convolution Layer 2 Hyper Parameters\n",
    "    hyper_params_c2 = {}\n",
    "    hyper_params_c2[\"stride\"] = 2\n",
    "    hyper_params_c2[\"pad\"] = 0\n",
    "    \n",
    "    # Pooling Layer 2 Hyper Parameters\n",
    "    hyper_params_p2 = {}\n",
    "    hyper_params_p2[\"stride\"] = 1\n",
    "    hyper_params_p2[\"pad\"] = 0\n",
    "    hyper_params_p2[\"f\"] = 5\n",
    "    \n",
    "    hyper_params[\"c1\"] = hyper_params_c1\n",
    "    hyper_params[\"p1\"] = hyper_params_p1\n",
    "    \n",
    "    hyper_params[\"c2\"] = hyper_params_c2\n",
    "    hyper_params[\"p2\"] = hyper_params_p2\n",
    "    \n",
    "    return hyper_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convolution nH_prev, f, pad, stride---------------\n",
      "64 4 1 2\n",
      "convolution m, nH, nW, nC---------------\n",
      "1020 32 32 8\n",
      "Dimension after padding(1020, 66, 66, 3)\n",
      "Pooling (m, nH_prev, nW_prev, nC_prev---------------\n",
      "1020 32 32 8\n",
      "Pooling f, stride\n",
      "5 1\n",
      "convolution nH_prev, f, pad, stride---------------\n",
      "28 4 0 2\n",
      "convolution m, nH, nW, nC---------------\n",
      "1020 13 13 16\n",
      "Dimension after padding(1020, 28, 28, 8)\n",
      "Pooling (m, nH_prev, nW_prev, nC_prev---------------\n",
      "1020 13 13 16\n",
      "Pooling f, stride\n",
      "5 1\n",
      "Shape before flattening is----\n",
      "(1020, 9, 9, 16)\n",
      "Shape after flattening is----\n",
      "(1020, 1296)\n",
      "Before sigmoid---\n",
      "[[ 17796.52907485  16495.51505015  14516.22359186 ...,  16305.06080427\n",
      "   16119.15615225  18847.37054686]\n",
      " [  2179.038839     2391.60631008   3246.51567801 ...,   3109.78190771\n",
      "    2952.4355778    1659.983982  ]\n",
      " [  -786.77147639   -737.1381775    -487.35145498 ...,   -293.42698422\n",
      "    -382.7701899   -1146.89743726]\n",
      " [  -168.33529833   -418.64866213    402.06720403 ...,     93.70100858\n",
      "    -545.60128819    357.74194818]\n",
      " [ -1681.32643242  -2437.21588916  -1199.36011789 ...,   -809.58524666\n",
      "   -1452.18959696  -1224.86717766]\n",
      " [  4798.34069433   4568.08487022   5433.21514178 ...,   6155.58211753\n",
      "    4961.13945918   4322.73761619]]\n",
      "After sigmoid---\n",
      "[[  1.00000000e+000   1.00000000e+000   1.00000000e+000 ...,\n",
      "    1.00000000e+000   1.00000000e+000   1.00000000e+000]\n",
      " [  1.00000000e+000   1.00000000e+000   1.00000000e+000 ...,\n",
      "    1.00000000e+000   1.00000000e+000   1.00000000e+000]\n",
      " [  0.00000000e+000   0.00000000e+000   2.21795308e-212 ...,\n",
      "    3.68366317e-128   5.82128267e-167   0.00000000e+000]\n",
      " [  7.81463728e-074   1.52474135e-182   1.00000000e+000 ...,\n",
      "    1.00000000e+000   1.11781831e-237   1.00000000e+000]\n",
      " [  0.00000000e+000   0.00000000e+000   0.00000000e+000 ...,\n",
      "    0.00000000e+000   0.00000000e+000   0.00000000e+000]\n",
      " [  1.00000000e+000   1.00000000e+000   1.00000000e+000 ...,\n",
      "    1.00000000e+000   1.00000000e+000   1.00000000e+000]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meenakshiparyani/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "cache = {}\n",
    "cache[\"A0\"] = X_train_norm\n",
    "params = initialize_parameters(input_channl=3, conv1_f=4, channl_1=8, conv2_f=4, channl_2=16, \n",
    "                          input_size=1296, fc1_size=108, fc2_size=6)\n",
    "hyper_params = initialize_hyper_params()\n",
    "cache = forward_propagate(cache, hyper_params, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key A0\n",
      "key Z1c\n",
      "key A1c\n",
      "key A1p\n",
      "key Z2c\n",
      "key A2c\n",
      "key A2p\n",
      "key A3\n",
      "key Z4\n",
      "key A4\n",
      "key Z5\n",
      "key A5\n",
      "shape\n",
      "(1020, 13, 13, 16)\n",
      "(1020, 13, 13, 16)\n",
      "Dimension after padding(1020, 28, 28, 8)\n",
      "Dimension after padding(1020, 28, 28, 8)\n",
      "Dimension after padding(1020, 66, 66, 3)\n",
      "Dimension after padding(1020, 66, 66, 3)\n",
      "dW5\n",
      "db5\n",
      "dW4\n",
      "db4\n",
      "dW2\n",
      "db2\n",
      "dW1\n",
      "db1\n"
     ]
    }
   ],
   "source": [
    "for key, value in cache.items():\n",
    "    print(\"key \" + str(key))\n",
    "gradients = backward_propagate(y_train_encoded, cache, hyper_params, params)\n",
    "for key, value in gradients.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from __future__ import division\n",
    "# import decimal\n",
    "# m,n = cache[\"Z5\"].shape\n",
    "# for i in range(m):\n",
    "#     for j in range(n):\n",
    "#         z = cache[\"Z5\"][i][j]\n",
    "#         if(z>=0):\n",
    "#             z = np.exp(-z)\n",
    "#             cache[\"Z5\"][i][j] = 1./(1. + z)\n",
    "#         else:\n",
    "#             z = np.exp(z)\n",
    "#             cache[\"Z5\"][i][j] = z/(1. + z)\n",
    "            \n",
    "# print( cache[\"Z5\"])\n",
    "# print( cache[\"A5\"])\n",
    "# y_train_encoded = one_hot_encode(y_train)\n",
    "# # print(y_train_encoded)\n",
    "# # # print(y_train_encoded.shape)\n",
    "# # # print(cache[\"A5\"].transpose())\n",
    "# cost = cross_entropy(cache[\"A5\"].transpose(),y_train_encoded)\n",
    "# print(cost)\n",
    "\n",
    "# # # print(cache[\"Z5\"])\n",
    "# # print()\n",
    "# # answer = 1.0/(1.0+np.exp(-cache[\"Z4\"]))\n",
    "# # print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
